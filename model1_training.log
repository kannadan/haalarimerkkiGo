I0616 09:01:36.889830  3392 caffe.cpp:218] Using GPUs 0
I0616 09:01:36.918998  3392 caffe.cpp:223] GPU 0: GeForce GT 740M
I0616 09:01:37.142024  3392 solver.cpp:44] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
base_lr: 0.001
display: 50
max_iter: 40000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2500
snapshot: 5000
snapshot_prefix: "/home/jondan/Documents/Ohjelmat/haalarimerkkiGo/caffe_model_1"
solver_mode: GPU
device_id: 0
net: "/home/jondan/Documents/Ohjelmat/haalarimerkkiGo/caffenet_train_val_1.prototxt"
train_state {
  level: 0
  stage: ""
}
I0616 09:01:37.142218  3392 solver.cpp:87] Creating training net from net file: /home/jondan/Documents/Ohjelmat/haalarimerkkiGo/caffenet_train_val_1.prototxt
I0616 09:01:37.142562  3392 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0616 09:01:37.142604  3392 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0616 09:01:37.142789  3392 net.cpp:51] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/jondan/Documents/Ohjelmat/haalarimerkkiGo/mean.binaryproto"
  }
  data_param {
    source: "/home/jondan/Documents/Ohjelmat/haalarimerkkiGo/training_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0616 09:01:37.142937  3392 layer_factory.hpp:77] Creating layer data
I0616 09:01:37.143074  3392 db_lmdb.cpp:35] Opened lmdb /home/jondan/Documents/Ohjelmat/haalarimerkkiGo/training_lmdb
I0616 09:01:37.143110  3392 net.cpp:84] Creating Layer data
I0616 09:01:37.143122  3392 net.cpp:380] data -> data
I0616 09:01:37.143157  3392 net.cpp:380] data -> label
I0616 09:01:37.143179  3392 data_transformer.cpp:25] Loading mean file from: /home/jondan/Documents/Ohjelmat/haalarimerkkiGo/mean.binaryproto
I0616 09:01:37.146355  3392 data_layer.cpp:45] output data size: 64,3,227,227
I0616 09:01:37.298154  3392 net.cpp:122] Setting up data
I0616 09:01:37.298190  3392 net.cpp:129] Top shape: 64 3 227 227 (9893568)
I0616 09:01:37.298202  3392 net.cpp:129] Top shape: 64 (64)
I0616 09:01:37.298207  3392 net.cpp:137] Memory required for data: 39574528
I0616 09:01:37.298221  3392 layer_factory.hpp:77] Creating layer conv1
I0616 09:01:37.298251  3392 net.cpp:84] Creating Layer conv1
I0616 09:01:37.298264  3392 net.cpp:406] conv1 <- data
I0616 09:01:37.298281  3392 net.cpp:380] conv1 -> conv1
I0616 09:01:37.301923  3392 net.cpp:122] Setting up conv1
I0616 09:01:37.301950  3392 net.cpp:129] Top shape: 64 96 55 55 (18585600)
I0616 09:01:37.301954  3392 net.cpp:137] Memory required for data: 113916928
I0616 09:01:37.301981  3392 layer_factory.hpp:77] Creating layer relu1
I0616 09:01:37.302001  3392 net.cpp:84] Creating Layer relu1
I0616 09:01:37.302012  3392 net.cpp:406] relu1 <- conv1
I0616 09:01:37.302023  3392 net.cpp:367] relu1 -> conv1 (in-place)
I0616 09:01:37.302042  3392 net.cpp:122] Setting up relu1
I0616 09:01:37.302053  3392 net.cpp:129] Top shape: 64 96 55 55 (18585600)
I0616 09:01:37.302063  3392 net.cpp:137] Memory required for data: 188259328
I0616 09:01:37.302069  3392 layer_factory.hpp:77] Creating layer pool1
I0616 09:01:37.302085  3392 net.cpp:84] Creating Layer pool1
I0616 09:01:37.302094  3392 net.cpp:406] pool1 <- conv1
I0616 09:01:37.302104  3392 net.cpp:380] pool1 -> pool1
I0616 09:01:37.302170  3392 net.cpp:122] Setting up pool1
I0616 09:01:37.302181  3392 net.cpp:129] Top shape: 64 96 27 27 (4478976)
I0616 09:01:37.302186  3392 net.cpp:137] Memory required for data: 206175232
I0616 09:01:37.302212  3392 layer_factory.hpp:77] Creating layer norm1
I0616 09:01:37.302222  3392 net.cpp:84] Creating Layer norm1
I0616 09:01:37.302227  3392 net.cpp:406] norm1 <- pool1
I0616 09:01:37.302232  3392 net.cpp:380] norm1 -> norm1
I0616 09:01:37.325830  3392 net.cpp:122] Setting up norm1
I0616 09:01:37.325858  3392 net.cpp:129] Top shape: 64 96 27 27 (4478976)
I0616 09:01:37.325865  3392 net.cpp:137] Memory required for data: 224091136
I0616 09:01:37.325873  3392 layer_factory.hpp:77] Creating layer conv2
I0616 09:01:37.325896  3392 net.cpp:84] Creating Layer conv2
I0616 09:01:37.325907  3392 net.cpp:406] conv2 <- norm1
I0616 09:01:37.325922  3392 net.cpp:380] conv2 -> conv2
I0616 09:01:37.333175  3392 net.cpp:122] Setting up conv2
I0616 09:01:37.333219  3392 net.cpp:129] Top shape: 64 256 27 27 (11943936)
I0616 09:01:37.333225  3392 net.cpp:137] Memory required for data: 271866880
I0616 09:01:37.333263  3392 layer_factory.hpp:77] Creating layer relu2
I0616 09:01:37.333295  3392 net.cpp:84] Creating Layer relu2
I0616 09:01:37.333305  3392 net.cpp:406] relu2 <- conv2
I0616 09:01:37.333324  3392 net.cpp:367] relu2 -> conv2 (in-place)
I0616 09:01:37.333358  3392 net.cpp:122] Setting up relu2
I0616 09:01:37.333366  3392 net.cpp:129] Top shape: 64 256 27 27 (11943936)
I0616 09:01:37.333382  3392 net.cpp:137] Memory required for data: 319642624
I0616 09:01:37.333395  3392 layer_factory.hpp:77] Creating layer pool2
I0616 09:01:37.333420  3392 net.cpp:84] Creating Layer pool2
I0616 09:01:37.333427  3392 net.cpp:406] pool2 <- conv2
I0616 09:01:37.333446  3392 net.cpp:380] pool2 -> pool2
I0616 09:01:37.333513  3392 net.cpp:122] Setting up pool2
I0616 09:01:37.333523  3392 net.cpp:129] Top shape: 64 256 13 13 (2768896)
I0616 09:01:37.333529  3392 net.cpp:137] Memory required for data: 330718208
I0616 09:01:37.333535  3392 layer_factory.hpp:77] Creating layer norm2
I0616 09:01:37.333551  3392 net.cpp:84] Creating Layer norm2
I0616 09:01:37.333559  3392 net.cpp:406] norm2 <- pool2
I0616 09:01:37.333577  3392 net.cpp:380] norm2 -> norm2
I0616 09:01:37.333623  3392 net.cpp:122] Setting up norm2
I0616 09:01:37.333633  3392 net.cpp:129] Top shape: 64 256 13 13 (2768896)
I0616 09:01:37.333647  3392 net.cpp:137] Memory required for data: 341793792
I0616 09:01:37.333658  3392 layer_factory.hpp:77] Creating layer conv3
I0616 09:01:37.333686  3392 net.cpp:84] Creating Layer conv3
I0616 09:01:37.333693  3392 net.cpp:406] conv3 <- norm2
I0616 09:01:37.333712  3392 net.cpp:380] conv3 -> conv3
I0616 09:01:37.345530  3392 net.cpp:122] Setting up conv3
I0616 09:01:37.345564  3392 net.cpp:129] Top shape: 64 384 13 13 (4153344)
I0616 09:01:37.345571  3392 net.cpp:137] Memory required for data: 358407168
I0616 09:01:37.345607  3392 layer_factory.hpp:77] Creating layer relu3
I0616 09:01:37.345628  3392 net.cpp:84] Creating Layer relu3
I0616 09:01:37.345638  3392 net.cpp:406] relu3 <- conv3
I0616 09:01:37.345656  3392 net.cpp:367] relu3 -> conv3 (in-place)
I0616 09:01:37.345677  3392 net.cpp:122] Setting up relu3
I0616 09:01:37.345690  3392 net.cpp:129] Top shape: 64 384 13 13 (4153344)
I0616 09:01:37.345710  3392 net.cpp:137] Memory required for data: 375020544
I0616 09:01:37.345726  3392 layer_factory.hpp:77] Creating layer conv4
I0616 09:01:37.345757  3392 net.cpp:84] Creating Layer conv4
I0616 09:01:37.345763  3392 net.cpp:406] conv4 <- conv3
I0616 09:01:37.345782  3392 net.cpp:380] conv4 -> conv4
I0616 09:01:37.393501  3392 net.cpp:122] Setting up conv4
I0616 09:01:37.393545  3392 net.cpp:129] Top shape: 64 384 13 13 (4153344)
I0616 09:01:37.393553  3392 net.cpp:137] Memory required for data: 391633920
I0616 09:01:37.393566  3392 layer_factory.hpp:77] Creating layer relu4
I0616 09:01:37.393581  3392 net.cpp:84] Creating Layer relu4
I0616 09:01:37.393589  3392 net.cpp:406] relu4 <- conv4
I0616 09:01:37.393599  3392 net.cpp:367] relu4 -> conv4 (in-place)
I0616 09:01:37.393613  3392 net.cpp:122] Setting up relu4
I0616 09:01:37.393621  3392 net.cpp:129] Top shape: 64 384 13 13 (4153344)
I0616 09:01:37.393627  3392 net.cpp:137] Memory required for data: 408247296
I0616 09:01:37.393664  3392 layer_factory.hpp:77] Creating layer conv5
I0616 09:01:37.393683  3392 net.cpp:84] Creating Layer conv5
I0616 09:01:37.393692  3392 net.cpp:406] conv5 <- conv4
I0616 09:01:37.393705  3392 net.cpp:380] conv5 -> conv5
I0616 09:01:37.402062  3392 net.cpp:122] Setting up conv5
I0616 09:01:37.402112  3392 net.cpp:129] Top shape: 64 256 13 13 (2768896)
I0616 09:01:37.402118  3392 net.cpp:137] Memory required for data: 419322880
I0616 09:01:37.402137  3392 layer_factory.hpp:77] Creating layer relu5
I0616 09:01:37.402154  3392 net.cpp:84] Creating Layer relu5
I0616 09:01:37.402161  3392 net.cpp:406] relu5 <- conv5
I0616 09:01:37.402173  3392 net.cpp:367] relu5 -> conv5 (in-place)
I0616 09:01:37.402187  3392 net.cpp:122] Setting up relu5
I0616 09:01:37.402195  3392 net.cpp:129] Top shape: 64 256 13 13 (2768896)
I0616 09:01:37.402200  3392 net.cpp:137] Memory required for data: 430398464
I0616 09:01:37.402206  3392 layer_factory.hpp:77] Creating layer pool5
I0616 09:01:37.402216  3392 net.cpp:84] Creating Layer pool5
I0616 09:01:37.402223  3392 net.cpp:406] pool5 <- conv5
I0616 09:01:37.402231  3392 net.cpp:380] pool5 -> pool5
I0616 09:01:37.402292  3392 net.cpp:122] Setting up pool5
I0616 09:01:37.402304  3392 net.cpp:129] Top shape: 64 256 6 6 (589824)
I0616 09:01:37.402309  3392 net.cpp:137] Memory required for data: 432757760
I0616 09:01:37.402315  3392 layer_factory.hpp:77] Creating layer fc6
I0616 09:01:37.402331  3392 net.cpp:84] Creating Layer fc6
I0616 09:01:37.402338  3392 net.cpp:406] fc6 <- pool5
I0616 09:01:37.402348  3392 net.cpp:380] fc6 -> fc6
I0616 09:01:37.951539  3392 net.cpp:122] Setting up fc6
I0616 09:01:37.951575  3392 net.cpp:129] Top shape: 64 4096 (262144)
I0616 09:01:37.951581  3392 net.cpp:137] Memory required for data: 433806336
I0616 09:01:37.951593  3392 layer_factory.hpp:77] Creating layer relu6
I0616 09:01:37.951617  3392 net.cpp:84] Creating Layer relu6
I0616 09:01:37.951627  3392 net.cpp:406] relu6 <- fc6
I0616 09:01:37.951638  3392 net.cpp:367] relu6 -> fc6 (in-place)
I0616 09:01:37.951658  3392 net.cpp:122] Setting up relu6
I0616 09:01:37.951669  3392 net.cpp:129] Top shape: 64 4096 (262144)
I0616 09:01:37.951674  3392 net.cpp:137] Memory required for data: 434854912
I0616 09:01:37.951679  3392 layer_factory.hpp:77] Creating layer drop6
I0616 09:01:37.951689  3392 net.cpp:84] Creating Layer drop6
I0616 09:01:37.951697  3392 net.cpp:406] drop6 <- fc6
I0616 09:01:37.951705  3392 net.cpp:367] drop6 -> fc6 (in-place)
I0616 09:01:37.951750  3392 net.cpp:122] Setting up drop6
I0616 09:01:37.951766  3392 net.cpp:129] Top shape: 64 4096 (262144)
I0616 09:01:37.951781  3392 net.cpp:137] Memory required for data: 435903488
I0616 09:01:37.951784  3392 layer_factory.hpp:77] Creating layer fc7
I0616 09:01:37.951793  3392 net.cpp:84] Creating Layer fc7
I0616 09:01:37.951797  3392 net.cpp:406] fc7 <- fc6
I0616 09:01:37.951803  3392 net.cpp:380] fc7 -> fc7
I0616 09:01:38.176849  3392 net.cpp:122] Setting up fc7
I0616 09:01:38.176892  3392 net.cpp:129] Top shape: 64 4096 (262144)
I0616 09:01:38.176898  3392 net.cpp:137] Memory required for data: 436952064
I0616 09:01:38.176910  3392 layer_factory.hpp:77] Creating layer relu7
I0616 09:01:38.176923  3392 net.cpp:84] Creating Layer relu7
I0616 09:01:38.176929  3392 net.cpp:406] relu7 <- fc7
I0616 09:01:38.176936  3392 net.cpp:367] relu7 -> fc7 (in-place)
I0616 09:01:38.176952  3392 net.cpp:122] Setting up relu7
I0616 09:01:38.176964  3392 net.cpp:129] Top shape: 64 4096 (262144)
I0616 09:01:38.176970  3392 net.cpp:137] Memory required for data: 438000640
I0616 09:01:38.176980  3392 layer_factory.hpp:77] Creating layer drop7
I0616 09:01:38.176990  3392 net.cpp:84] Creating Layer drop7
I0616 09:01:38.176997  3392 net.cpp:406] drop7 <- fc7
I0616 09:01:38.177007  3392 net.cpp:367] drop7 -> fc7 (in-place)
I0616 09:01:38.177045  3392 net.cpp:122] Setting up drop7
I0616 09:01:38.177064  3392 net.cpp:129] Top shape: 64 4096 (262144)
I0616 09:01:38.177079  3392 net.cpp:137] Memory required for data: 439049216
I0616 09:01:38.177104  3392 layer_factory.hpp:77] Creating layer fc8
I0616 09:01:38.177119  3392 net.cpp:84] Creating Layer fc8
I0616 09:01:38.177125  3392 net.cpp:406] fc8 <- fc7
I0616 09:01:38.177136  3392 net.cpp:380] fc8 -> fc8
I0616 09:01:38.177886  3392 net.cpp:122] Setting up fc8
I0616 09:01:38.177902  3392 net.cpp:129] Top shape: 64 2 (128)
I0616 09:01:38.177908  3392 net.cpp:137] Memory required for data: 439049728
I0616 09:01:38.177920  3392 layer_factory.hpp:77] Creating layer loss
I0616 09:01:38.177939  3392 net.cpp:84] Creating Layer loss
I0616 09:01:38.177947  3392 net.cpp:406] loss <- fc8
I0616 09:01:38.177954  3392 net.cpp:406] loss <- label
I0616 09:01:38.177968  3392 net.cpp:380] loss -> loss
I0616 09:01:38.177989  3392 layer_factory.hpp:77] Creating layer loss
I0616 09:01:38.178081  3392 net.cpp:122] Setting up loss
I0616 09:01:38.178092  3392 net.cpp:129] Top shape: (1)
I0616 09:01:38.178098  3392 net.cpp:132]     with loss weight 1
I0616 09:01:38.178122  3392 net.cpp:137] Memory required for data: 439049732
I0616 09:01:38.178129  3392 net.cpp:198] loss needs backward computation.
I0616 09:01:38.178141  3392 net.cpp:198] fc8 needs backward computation.
I0616 09:01:38.178148  3392 net.cpp:198] drop7 needs backward computation.
I0616 09:01:38.178156  3392 net.cpp:198] relu7 needs backward computation.
I0616 09:01:38.178162  3392 net.cpp:198] fc7 needs backward computation.
I0616 09:01:38.178169  3392 net.cpp:198] drop6 needs backward computation.
I0616 09:01:38.178176  3392 net.cpp:198] relu6 needs backward computation.
I0616 09:01:38.178184  3392 net.cpp:198] fc6 needs backward computation.
I0616 09:01:38.178191  3392 net.cpp:198] pool5 needs backward computation.
I0616 09:01:38.178200  3392 net.cpp:198] relu5 needs backward computation.
I0616 09:01:38.178205  3392 net.cpp:198] conv5 needs backward computation.
I0616 09:01:38.178213  3392 net.cpp:198] relu4 needs backward computation.
I0616 09:01:38.178221  3392 net.cpp:198] conv4 needs backward computation.
I0616 09:01:38.178231  3392 net.cpp:198] relu3 needs backward computation.
I0616 09:01:38.178238  3392 net.cpp:198] conv3 needs backward computation.
I0616 09:01:38.178247  3392 net.cpp:198] norm2 needs backward computation.
I0616 09:01:38.178256  3392 net.cpp:198] pool2 needs backward computation.
I0616 09:01:38.178262  3392 net.cpp:198] relu2 needs backward computation.
I0616 09:01:38.178269  3392 net.cpp:198] conv2 needs backward computation.
I0616 09:01:38.178277  3392 net.cpp:198] norm1 needs backward computation.
I0616 09:01:38.178284  3392 net.cpp:198] pool1 needs backward computation.
I0616 09:01:38.178292  3392 net.cpp:198] relu1 needs backward computation.
I0616 09:01:38.178299  3392 net.cpp:198] conv1 needs backward computation.
I0616 09:01:38.178306  3392 net.cpp:200] data does not need backward computation.
I0616 09:01:38.178313  3392 net.cpp:242] This network produces output loss
I0616 09:01:38.178334  3392 net.cpp:255] Network initialization done.
I0616 09:01:38.178664  3392 solver.cpp:172] Creating test net (#0) specified by net file: /home/jondan/Documents/Ohjelmat/haalarimerkkiGo/caffenet_train_val_1.prototxt
I0616 09:01:38.178711  3392 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0616 09:01:38.178913  3392 net.cpp:51] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/jondan/Documents/Ohjelmat/haalarimerkkiGo/mean.binaryproto"
  }
  data_param {
    source: "/home/jondan/Documents/Ohjelmat/haalarimerkkiGo/validation_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0616 09:01:38.179076  3392 layer_factory.hpp:77] Creating layer data
I0616 09:01:38.179154  3392 db_lmdb.cpp:35] Opened lmdb /home/jondan/Documents/Ohjelmat/haalarimerkkiGo/validation_lmdb
I0616 09:01:38.179175  3392 net.cpp:84] Creating Layer data
I0616 09:01:38.179186  3392 net.cpp:380] data -> data
I0616 09:01:38.179199  3392 net.cpp:380] data -> label
I0616 09:01:38.179210  3392 data_transformer.cpp:25] Loading mean file from: /home/jondan/Documents/Ohjelmat/haalarimerkkiGo/mean.binaryproto
I0616 09:01:38.181264  3392 data_layer.cpp:45] output data size: 50,3,227,227
I0616 09:01:38.307106  3392 net.cpp:122] Setting up data
I0616 09:01:38.307144  3392 net.cpp:129] Top shape: 50 3 227 227 (7729350)
I0616 09:01:38.307157  3392 net.cpp:129] Top shape: 50 (50)
I0616 09:01:38.307163  3392 net.cpp:137] Memory required for data: 30917600
I0616 09:01:38.307174  3392 layer_factory.hpp:77] Creating layer label_data_1_split
I0616 09:01:38.307199  3392 net.cpp:84] Creating Layer label_data_1_split
I0616 09:01:38.307209  3392 net.cpp:406] label_data_1_split <- label
I0616 09:01:38.307221  3392 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0616 09:01:38.307240  3392 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0616 09:01:38.307306  3392 net.cpp:122] Setting up label_data_1_split
I0616 09:01:38.307317  3392 net.cpp:129] Top shape: 50 (50)
I0616 09:01:38.307324  3392 net.cpp:129] Top shape: 50 (50)
I0616 09:01:38.307329  3392 net.cpp:137] Memory required for data: 30918000
I0616 09:01:38.307335  3392 layer_factory.hpp:77] Creating layer conv1
I0616 09:01:38.307355  3392 net.cpp:84] Creating Layer conv1
I0616 09:01:38.307363  3392 net.cpp:406] conv1 <- data
I0616 09:01:38.307374  3392 net.cpp:380] conv1 -> conv1
I0616 09:01:38.308040  3392 net.cpp:122] Setting up conv1
I0616 09:01:38.308056  3392 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0616 09:01:38.308063  3392 net.cpp:137] Memory required for data: 88998000
I0616 09:01:38.308080  3392 layer_factory.hpp:77] Creating layer relu1
I0616 09:01:38.308091  3392 net.cpp:84] Creating Layer relu1
I0616 09:01:38.308099  3392 net.cpp:406] relu1 <- conv1
I0616 09:01:38.308109  3392 net.cpp:367] relu1 -> conv1 (in-place)
I0616 09:01:38.308123  3392 net.cpp:122] Setting up relu1
I0616 09:01:38.308135  3392 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0616 09:01:38.308141  3392 net.cpp:137] Memory required for data: 147078000
I0616 09:01:38.308148  3392 layer_factory.hpp:77] Creating layer pool1
I0616 09:01:38.308161  3392 net.cpp:84] Creating Layer pool1
I0616 09:01:38.308167  3392 net.cpp:406] pool1 <- conv1
I0616 09:01:38.308176  3392 net.cpp:380] pool1 -> pool1
I0616 09:01:38.308224  3392 net.cpp:122] Setting up pool1
I0616 09:01:38.308235  3392 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0616 09:01:38.308243  3392 net.cpp:137] Memory required for data: 161074800
I0616 09:01:38.308250  3392 layer_factory.hpp:77] Creating layer norm1
I0616 09:01:38.308261  3392 net.cpp:84] Creating Layer norm1
I0616 09:01:38.308269  3392 net.cpp:406] norm1 <- pool1
I0616 09:01:38.308277  3392 net.cpp:380] norm1 -> norm1
I0616 09:01:38.308320  3392 net.cpp:122] Setting up norm1
I0616 09:01:38.308328  3392 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0616 09:01:38.308334  3392 net.cpp:137] Memory required for data: 175071600
I0616 09:01:38.308341  3392 layer_factory.hpp:77] Creating layer conv2
I0616 09:01:38.308357  3392 net.cpp:84] Creating Layer conv2
I0616 09:01:38.308363  3392 net.cpp:406] conv2 <- norm1
I0616 09:01:38.308373  3392 net.cpp:380] conv2 -> conv2
I0616 09:01:38.333380  3392 net.cpp:122] Setting up conv2
I0616 09:01:38.333417  3392 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0616 09:01:38.333426  3392 net.cpp:137] Memory required for data: 212396400
I0616 09:01:38.333447  3392 layer_factory.hpp:77] Creating layer relu2
I0616 09:01:38.333480  3392 net.cpp:84] Creating Layer relu2
I0616 09:01:38.333492  3392 net.cpp:406] relu2 <- conv2
I0616 09:01:38.333504  3392 net.cpp:367] relu2 -> conv2 (in-place)
I0616 09:01:38.333520  3392 net.cpp:122] Setting up relu2
I0616 09:01:38.333533  3392 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0616 09:01:38.333539  3392 net.cpp:137] Memory required for data: 249721200
I0616 09:01:38.333546  3392 layer_factory.hpp:77] Creating layer pool2
I0616 09:01:38.333560  3392 net.cpp:84] Creating Layer pool2
I0616 09:01:38.333567  3392 net.cpp:406] pool2 <- conv2
I0616 09:01:38.333577  3392 net.cpp:380] pool2 -> pool2
I0616 09:01:38.333647  3392 net.cpp:122] Setting up pool2
I0616 09:01:38.333658  3392 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0616 09:01:38.333664  3392 net.cpp:137] Memory required for data: 258374000
I0616 09:01:38.333670  3392 layer_factory.hpp:77] Creating layer norm2
I0616 09:01:38.333683  3392 net.cpp:84] Creating Layer norm2
I0616 09:01:38.333691  3392 net.cpp:406] norm2 <- pool2
I0616 09:01:38.333701  3392 net.cpp:380] norm2 -> norm2
I0616 09:01:38.333762  3392 net.cpp:122] Setting up norm2
I0616 09:01:38.333796  3392 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0616 09:01:38.333802  3392 net.cpp:137] Memory required for data: 267026800
I0616 09:01:38.333808  3392 layer_factory.hpp:77] Creating layer conv3
I0616 09:01:38.333825  3392 net.cpp:84] Creating Layer conv3
I0616 09:01:38.333834  3392 net.cpp:406] conv3 <- norm2
I0616 09:01:38.333847  3392 net.cpp:380] conv3 -> conv3
I0616 09:01:38.346029  3392 net.cpp:122] Setting up conv3
I0616 09:01:38.346065  3392 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0616 09:01:38.346072  3392 net.cpp:137] Memory required for data: 280006000
I0616 09:01:38.346093  3392 layer_factory.hpp:77] Creating layer relu3
I0616 09:01:38.346112  3392 net.cpp:84] Creating Layer relu3
I0616 09:01:38.346123  3392 net.cpp:406] relu3 <- conv3
I0616 09:01:38.346134  3392 net.cpp:367] relu3 -> conv3 (in-place)
I0616 09:01:38.346150  3392 net.cpp:122] Setting up relu3
I0616 09:01:38.346161  3392 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0616 09:01:38.346168  3392 net.cpp:137] Memory required for data: 292985200
I0616 09:01:38.346174  3392 layer_factory.hpp:77] Creating layer conv4
I0616 09:01:38.346191  3392 net.cpp:84] Creating Layer conv4
I0616 09:01:38.346199  3392 net.cpp:406] conv4 <- conv3
I0616 09:01:38.346210  3392 net.cpp:380] conv4 -> conv4
I0616 09:01:38.389328  3392 net.cpp:122] Setting up conv4
I0616 09:01:38.389370  3392 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0616 09:01:38.389379  3392 net.cpp:137] Memory required for data: 305964400
I0616 09:01:38.389397  3392 layer_factory.hpp:77] Creating layer relu4
I0616 09:01:38.389420  3392 net.cpp:84] Creating Layer relu4
I0616 09:01:38.389430  3392 net.cpp:406] relu4 <- conv4
I0616 09:01:38.389443  3392 net.cpp:367] relu4 -> conv4 (in-place)
I0616 09:01:38.389461  3392 net.cpp:122] Setting up relu4
I0616 09:01:38.389473  3392 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0616 09:01:38.389484  3392 net.cpp:137] Memory required for data: 318943600
I0616 09:01:38.389493  3392 layer_factory.hpp:77] Creating layer conv5
I0616 09:01:38.389510  3392 net.cpp:84] Creating Layer conv5
I0616 09:01:38.389518  3392 net.cpp:406] conv5 <- conv4
I0616 09:01:38.389529  3392 net.cpp:380] conv5 -> conv5
I0616 09:01:38.397359  3392 net.cpp:122] Setting up conv5
I0616 09:01:38.397399  3392 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0616 09:01:38.397408  3392 net.cpp:137] Memory required for data: 327596400
I0616 09:01:38.397430  3392 layer_factory.hpp:77] Creating layer relu5
I0616 09:01:38.397449  3392 net.cpp:84] Creating Layer relu5
I0616 09:01:38.397469  3392 net.cpp:406] relu5 <- conv5
I0616 09:01:38.397481  3392 net.cpp:367] relu5 -> conv5 (in-place)
I0616 09:01:38.397496  3392 net.cpp:122] Setting up relu5
I0616 09:01:38.397506  3392 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0616 09:01:38.397512  3392 net.cpp:137] Memory required for data: 336249200
I0616 09:01:38.397543  3392 layer_factory.hpp:77] Creating layer pool5
I0616 09:01:38.397562  3392 net.cpp:84] Creating Layer pool5
I0616 09:01:38.397569  3392 net.cpp:406] pool5 <- conv5
I0616 09:01:38.397580  3392 net.cpp:380] pool5 -> pool5
I0616 09:01:38.397668  3392 net.cpp:122] Setting up pool5
I0616 09:01:38.397683  3392 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0616 09:01:38.397691  3392 net.cpp:137] Memory required for data: 338092400
I0616 09:01:38.397696  3392 layer_factory.hpp:77] Creating layer fc6
I0616 09:01:38.397711  3392 net.cpp:84] Creating Layer fc6
I0616 09:01:38.397718  3392 net.cpp:406] fc6 <- pool5
I0616 09:01:38.397729  3392 net.cpp:380] fc6 -> fc6
I0616 09:01:38.824631  3392 net.cpp:122] Setting up fc6
I0616 09:01:38.824667  3392 net.cpp:129] Top shape: 50 4096 (204800)
I0616 09:01:38.824686  3392 net.cpp:137] Memory required for data: 338911600
I0616 09:01:38.824702  3392 layer_factory.hpp:77] Creating layer relu6
I0616 09:01:38.824719  3392 net.cpp:84] Creating Layer relu6
I0616 09:01:38.824728  3392 net.cpp:406] relu6 <- fc6
I0616 09:01:38.824739  3392 net.cpp:367] relu6 -> fc6 (in-place)
I0616 09:01:38.824755  3392 net.cpp:122] Setting up relu6
I0616 09:01:38.824764  3392 net.cpp:129] Top shape: 50 4096 (204800)
I0616 09:01:38.824771  3392 net.cpp:137] Memory required for data: 339730800
I0616 09:01:38.824777  3392 layer_factory.hpp:77] Creating layer drop6
I0616 09:01:38.824787  3392 net.cpp:84] Creating Layer drop6
I0616 09:01:38.824793  3392 net.cpp:406] drop6 <- fc6
I0616 09:01:38.824801  3392 net.cpp:367] drop6 -> fc6 (in-place)
I0616 09:01:38.824853  3392 net.cpp:122] Setting up drop6
I0616 09:01:38.824875  3392 net.cpp:129] Top shape: 50 4096 (204800)
I0616 09:01:38.824880  3392 net.cpp:137] Memory required for data: 340550000
I0616 09:01:38.824898  3392 layer_factory.hpp:77] Creating layer fc7
I0616 09:01:38.824911  3392 net.cpp:84] Creating Layer fc7
I0616 09:01:38.824919  3392 net.cpp:406] fc7 <- fc6
I0616 09:01:38.824930  3392 net.cpp:380] fc7 -> fc7
I0616 09:01:39.008862  3392 net.cpp:122] Setting up fc7
I0616 09:01:39.008903  3392 net.cpp:129] Top shape: 50 4096 (204800)
I0616 09:01:39.008909  3392 net.cpp:137] Memory required for data: 341369200
I0616 09:01:39.008937  3392 layer_factory.hpp:77] Creating layer relu7
I0616 09:01:39.008954  3392 net.cpp:84] Creating Layer relu7
I0616 09:01:39.008965  3392 net.cpp:406] relu7 <- fc7
I0616 09:01:39.008980  3392 net.cpp:367] relu7 -> fc7 (in-place)
I0616 09:01:39.008997  3392 net.cpp:122] Setting up relu7
I0616 09:01:39.009008  3392 net.cpp:129] Top shape: 50 4096 (204800)
I0616 09:01:39.009014  3392 net.cpp:137] Memory required for data: 342188400
I0616 09:01:39.009022  3392 layer_factory.hpp:77] Creating layer drop7
I0616 09:01:39.009033  3392 net.cpp:84] Creating Layer drop7
I0616 09:01:39.009047  3392 net.cpp:406] drop7 <- fc7
I0616 09:01:39.009058  3392 net.cpp:367] drop7 -> fc7 (in-place)
I0616 09:01:39.009104  3392 net.cpp:122] Setting up drop7
I0616 09:01:39.009115  3392 net.cpp:129] Top shape: 50 4096 (204800)
I0616 09:01:39.009121  3392 net.cpp:137] Memory required for data: 343007600
I0616 09:01:39.009127  3392 layer_factory.hpp:77] Creating layer fc8
I0616 09:01:39.009142  3392 net.cpp:84] Creating Layer fc8
I0616 09:01:39.009150  3392 net.cpp:406] fc8 <- fc7
I0616 09:01:39.009160  3392 net.cpp:380] fc8 -> fc8
I0616 09:01:39.009384  3392 net.cpp:122] Setting up fc8
I0616 09:01:39.009398  3392 net.cpp:129] Top shape: 50 2 (100)
I0616 09:01:39.009407  3392 net.cpp:137] Memory required for data: 343008000
I0616 09:01:39.009418  3392 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0616 09:01:39.009429  3392 net.cpp:84] Creating Layer fc8_fc8_0_split
I0616 09:01:39.009438  3392 net.cpp:406] fc8_fc8_0_split <- fc8
I0616 09:01:39.009446  3392 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0616 09:01:39.009460  3392 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0616 09:01:39.009510  3392 net.cpp:122] Setting up fc8_fc8_0_split
I0616 09:01:39.009521  3392 net.cpp:129] Top shape: 50 2 (100)
I0616 09:01:39.009528  3392 net.cpp:129] Top shape: 50 2 (100)
I0616 09:01:39.009552  3392 net.cpp:137] Memory required for data: 343008800
I0616 09:01:39.009558  3392 layer_factory.hpp:77] Creating layer accuracy
I0616 09:01:39.009575  3392 net.cpp:84] Creating Layer accuracy
I0616 09:01:39.009582  3392 net.cpp:406] accuracy <- fc8_fc8_0_split_0
I0616 09:01:39.009590  3392 net.cpp:406] accuracy <- label_data_1_split_0
I0616 09:01:39.009606  3392 net.cpp:380] accuracy -> accuracy
I0616 09:01:39.009623  3392 net.cpp:122] Setting up accuracy
I0616 09:01:39.009631  3392 net.cpp:129] Top shape: (1)
I0616 09:01:39.009639  3392 net.cpp:137] Memory required for data: 343008804
I0616 09:01:39.009644  3392 layer_factory.hpp:77] Creating layer loss
I0616 09:01:39.009654  3392 net.cpp:84] Creating Layer loss
I0616 09:01:39.009661  3392 net.cpp:406] loss <- fc8_fc8_0_split_1
I0616 09:01:39.009670  3392 net.cpp:406] loss <- label_data_1_split_1
I0616 09:01:39.009680  3392 net.cpp:380] loss -> loss
I0616 09:01:39.009694  3392 layer_factory.hpp:77] Creating layer loss
I0616 09:01:39.009794  3392 net.cpp:122] Setting up loss
I0616 09:01:39.009804  3392 net.cpp:129] Top shape: (1)
I0616 09:01:39.009810  3392 net.cpp:132]     with loss weight 1
I0616 09:01:39.009827  3392 net.cpp:137] Memory required for data: 343008808
I0616 09:01:39.009835  3392 net.cpp:198] loss needs backward computation.
I0616 09:01:39.009843  3392 net.cpp:200] accuracy does not need backward computation.
I0616 09:01:39.009852  3392 net.cpp:198] fc8_fc8_0_split needs backward computation.
I0616 09:01:39.009861  3392 net.cpp:198] fc8 needs backward computation.
I0616 09:01:39.009867  3392 net.cpp:198] drop7 needs backward computation.
I0616 09:01:39.009874  3392 net.cpp:198] relu7 needs backward computation.
I0616 09:01:39.009881  3392 net.cpp:198] fc7 needs backward computation.
I0616 09:01:39.009886  3392 net.cpp:198] drop6 needs backward computation.
I0616 09:01:39.009892  3392 net.cpp:198] relu6 needs backward computation.
I0616 09:01:39.009898  3392 net.cpp:198] fc6 needs backward computation.
I0616 09:01:39.009904  3392 net.cpp:198] pool5 needs backward computation.
I0616 09:01:39.009912  3392 net.cpp:198] relu5 needs backward computation.
I0616 09:01:39.009918  3392 net.cpp:198] conv5 needs backward computation.
I0616 09:01:39.009927  3392 net.cpp:198] relu4 needs backward computation.
I0616 09:01:39.009932  3392 net.cpp:198] conv4 needs backward computation.
I0616 09:01:39.009940  3392 net.cpp:198] relu3 needs backward computation.
I0616 09:01:39.009946  3392 net.cpp:198] conv3 needs backward computation.
I0616 09:01:39.009954  3392 net.cpp:198] norm2 needs backward computation.
I0616 09:01:39.009963  3392 net.cpp:198] pool2 needs backward computation.
I0616 09:01:39.009971  3392 net.cpp:198] relu2 needs backward computation.
I0616 09:01:39.009979  3392 net.cpp:198] conv2 needs backward computation.
I0616 09:01:39.009985  3392 net.cpp:198] norm1 needs backward computation.
I0616 09:01:39.009994  3392 net.cpp:198] pool1 needs backward computation.
I0616 09:01:39.010002  3392 net.cpp:198] relu1 needs backward computation.
I0616 09:01:39.010010  3392 net.cpp:198] conv1 needs backward computation.
I0616 09:01:39.010017  3392 net.cpp:200] label_data_1_split does not need backward computation.
I0616 09:01:39.010027  3392 net.cpp:200] data does not need backward computation.
I0616 09:01:39.010035  3392 net.cpp:242] This network produces output accuracy
I0616 09:01:39.010040  3392 net.cpp:242] This network produces output loss
I0616 09:01:39.010068  3392 net.cpp:255] Network initialization done.
I0616 09:01:39.010161  3392 solver.cpp:56] Solver scaffolding done.
I0616 09:01:39.010741  3392 caffe.cpp:248] Starting Optimization
I0616 09:01:39.010751  3392 solver.cpp:272] Solving CaffeNet
I0616 09:01:39.010756  3392 solver.cpp:273] Learning Rate Policy: step
I0616 09:01:39.013476  3392 solver.cpp:330] Iteration 0, Testing net (#0)
I0616 09:02:23.159036  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 09:03:08.806383  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 09:03:54.527312  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 09:04:39.805351  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 09:05:25.084103  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 09:06:10.669010  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 09:06:55.747889  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 09:07:40.830622  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 09:08:26.425040  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 09:09:11.491750  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 09:09:56.546618  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 09:10:42.160944  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 09:10:43.745172  3392 solver.cpp:397]     Test net output #0: accuracy = 0.49654
I0616 09:10:43.745218  3392 solver.cpp:397]     Test net output #1: loss = 0.723763 (* 1 = 0.723763 loss)
I0616 09:10:45.784262  3392 solver.cpp:218] Iteration 0 (0 iter/s, 546.778s/50 iters), loss = 0.913249
I0616 09:10:45.784333  3392 solver.cpp:237]     Train net output #0: loss = 0.913249 (* 1 = 0.913249 loss)
I0616 09:10:45.784358  3392 sgd_solver.cpp:105] Iteration 0, lr = 0.001
I0616 09:12:35.495127  3392 solver.cpp:218] Iteration 50 (0.45574 iter/s, 109.712s/50 iters), loss = 1.06104
I0616 09:12:35.495295  3392 solver.cpp:237]     Train net output #0: loss = 1.06104 (* 1 = 1.06104 loss)
I0616 09:12:35.495316  3392 sgd_solver.cpp:105] Iteration 50, lr = 0.001
I0616 09:14:25.171264  3392 solver.cpp:218] Iteration 100 (0.455885 iter/s, 109.677s/50 iters), loss = 1.0167
I0616 09:14:25.171365  3392 solver.cpp:237]     Train net output #0: loss = 1.0167 (* 1 = 1.0167 loss)
I0616 09:14:25.171376  3392 sgd_solver.cpp:105] Iteration 100, lr = 0.001
I0616 09:16:14.866969  3392 solver.cpp:218] Iteration 150 (0.455803 iter/s, 109.696s/50 iters), loss = 0.663265
I0616 09:16:14.867105  3392 solver.cpp:237]     Train net output #0: loss = 0.663265 (* 1 = 0.663265 loss)
I0616 09:16:14.867115  3392 sgd_solver.cpp:105] Iteration 150, lr = 0.001
I0616 09:18:04.575706  3392 solver.cpp:218] Iteration 200 (0.455749 iter/s, 109.709s/50 iters), loss = 0.732809
I0616 09:18:04.575850  3392 solver.cpp:237]     Train net output #0: loss = 0.732809 (* 1 = 0.732809 loss)
I0616 09:18:04.575863  3392 sgd_solver.cpp:105] Iteration 200, lr = 0.001
I0616 09:19:54.265812  3392 solver.cpp:218] Iteration 250 (0.455826 iter/s, 109.691s/50 iters), loss = 0.815791
I0616 09:19:54.265918  3392 solver.cpp:237]     Train net output #0: loss = 0.815791 (* 1 = 0.815791 loss)
I0616 09:19:54.265933  3392 sgd_solver.cpp:105] Iteration 250, lr = 0.001
I0616 09:21:43.937057  3392 solver.cpp:218] Iteration 300 (0.455905 iter/s, 109.672s/50 iters), loss = 0.802979
I0616 09:21:43.937198  3392 solver.cpp:237]     Train net output #0: loss = 0.802979 (* 1 = 0.802979 loss)
I0616 09:21:43.937214  3392 sgd_solver.cpp:105] Iteration 300, lr = 0.001
I0616 09:22:30.298360  3398 data_layer.cpp:73] Restarting data prefetching from start.
I0616 09:23:33.609649  3392 solver.cpp:218] Iteration 350 (0.455899 iter/s, 109.673s/50 iters), loss = 0.609353
I0616 09:23:33.609843  3392 solver.cpp:237]     Train net output #0: loss = 0.609353 (* 1 = 0.609353 loss)
I0616 09:23:33.609859  3392 sgd_solver.cpp:105] Iteration 350, lr = 0.001
I0616 09:25:23.303483  3392 solver.cpp:218] Iteration 400 (0.455811 iter/s, 109.695s/50 iters), loss = 0.654349
I0616 09:25:23.303584  3392 solver.cpp:237]     Train net output #0: loss = 0.654349 (* 1 = 0.654349 loss)
I0616 09:25:23.303614  3392 sgd_solver.cpp:105] Iteration 400, lr = 0.001
I0616 09:27:12.974723  3392 solver.cpp:218] Iteration 450 (0.455905 iter/s, 109.672s/50 iters), loss = 0.595915
I0616 09:27:12.974925  3392 solver.cpp:237]     Train net output #0: loss = 0.595915 (* 1 = 0.595915 loss)
I0616 09:27:12.974944  3392 sgd_solver.cpp:105] Iteration 450, lr = 0.001
I0616 09:29:02.628376  3392 solver.cpp:218] Iteration 500 (0.455978 iter/s, 109.654s/50 iters), loss = 0.66596
I0616 09:29:02.628494  3392 solver.cpp:237]     Train net output #0: loss = 0.66596 (* 1 = 0.66596 loss)
I0616 09:29:02.628511  3392 sgd_solver.cpp:105] Iteration 500, lr = 0.001
I0616 09:30:52.340971  3392 solver.cpp:218] Iteration 550 (0.455733 iter/s, 109.713s/50 iters), loss = 0.648184
I0616 09:30:52.341064  3392 solver.cpp:237]     Train net output #0: loss = 0.648184 (* 1 = 0.648184 loss)
I0616 09:30:52.341076  3392 sgd_solver.cpp:105] Iteration 550, lr = 0.001
I0616 09:32:42.002488  3392 solver.cpp:218] Iteration 600 (0.455945 iter/s, 109.662s/50 iters), loss = 0.586296
I0616 09:32:42.002602  3392 solver.cpp:237]     Train net output #0: loss = 0.586296 (* 1 = 0.586296 loss)
I0616 09:32:42.002619  3392 sgd_solver.cpp:105] Iteration 600, lr = 0.001
I0616 09:34:25.361788  3398 data_layer.cpp:73] Restarting data prefetching from start.
I0616 09:34:31.673269  3392 solver.cpp:218] Iteration 650 (0.455906 iter/s, 109.672s/50 iters), loss = 0.617605
I0616 09:34:31.673336  3392 solver.cpp:237]     Train net output #0: loss = 0.617605 (* 1 = 0.617605 loss)
I0616 09:34:31.673351  3392 sgd_solver.cpp:105] Iteration 650, lr = 0.001
I0616 09:36:21.334589  3392 solver.cpp:218] Iteration 700 (0.455945 iter/s, 109.662s/50 iters), loss = 0.618146
I0616 09:36:21.334694  3392 solver.cpp:237]     Train net output #0: loss = 0.618146 (* 1 = 0.618146 loss)
I0616 09:36:21.334707  3392 sgd_solver.cpp:105] Iteration 700, lr = 0.001
I0616 09:38:10.856554  3392 solver.cpp:218] Iteration 750 (0.456526 iter/s, 109.523s/50 iters), loss = 0.591968
I0616 09:38:10.856700  3392 solver.cpp:237]     Train net output #0: loss = 0.591968 (* 1 = 0.591968 loss)
I0616 09:38:10.856717  3392 sgd_solver.cpp:105] Iteration 750, lr = 0.001
I0616 09:40:00.911378  3392 solver.cpp:218] Iteration 800 (0.454316 iter/s, 110.056s/50 iters), loss = 0.577243
I0616 09:40:00.911479  3392 solver.cpp:237]     Train net output #0: loss = 0.577243 (* 1 = 0.577243 loss)
I0616 09:40:00.911496  3392 sgd_solver.cpp:105] Iteration 800, lr = 0.001
I0616 09:41:51.039836  3392 solver.cpp:218] Iteration 850 (0.454012 iter/s, 110.129s/50 iters), loss = 0.581229
I0616 09:41:51.039944  3392 solver.cpp:237]     Train net output #0: loss = 0.581229 (* 1 = 0.581229 loss)
I0616 09:41:51.040066  3392 sgd_solver.cpp:105] Iteration 850, lr = 0.001
I0616 09:43:40.802898  3392 solver.cpp:218] Iteration 900 (0.455523 iter/s, 109.764s/50 iters), loss = 0.617884
I0616 09:43:40.803041  3392 solver.cpp:237]     Train net output #0: loss = 0.617884 (* 1 = 0.617884 loss)
I0616 09:43:40.803051  3392 sgd_solver.cpp:105] Iteration 900, lr = 0.001
I0616 09:45:30.457336  3392 solver.cpp:218] Iteration 950 (0.455975 iter/s, 109.655s/50 iters), loss = 0.590284
I0616 09:45:30.457440  3392 solver.cpp:237]     Train net output #0: loss = 0.590284 (* 1 = 0.590284 loss)
I0616 09:45:30.457453  3392 sgd_solver.cpp:105] Iteration 950, lr = 0.001
I0616 09:46:19.002352  3398 data_layer.cpp:73] Restarting data prefetching from start.
I0616 09:47:17.260145  3392 solver.cpp:330] Iteration 1000, Testing net (#0)
I0616 09:48:01.654485  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 09:48:46.748308  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 09:49:32.371520  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 09:50:17.431417  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 09:51:02.500154  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 09:51:48.075915  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 09:52:33.149577  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 09:53:18.213465  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 09:54:03.814157  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 09:54:48.878479  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 09:55:33.964157  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 09:56:19.538487  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 09:56:21.130035  3392 solver.cpp:397]     Test net output #0: accuracy = 0.70724
I0616 09:56:21.130085  3392 solver.cpp:397]     Test net output #1: loss = 0.559699 (* 1 = 0.559699 loss)
I0616 09:56:23.111768  3392 solver.cpp:218] Iteration 1000 (0.0766096 iter/s, 652.66s/50 iters), loss = 0.609891
I0616 09:56:23.111831  3392 solver.cpp:237]     Train net output #0: loss = 0.609891 (* 1 = 0.609891 loss)
I0616 09:56:23.111841  3392 sgd_solver.cpp:105] Iteration 1000, lr = 0.001
I0616 09:58:12.810575  3392 solver.cpp:218] Iteration 1050 (0.45579 iter/s, 109.7s/50 iters), loss = 0.649583
I0616 09:58:12.810667  3392 solver.cpp:237]     Train net output #0: loss = 0.649583 (* 1 = 0.649583 loss)
I0616 09:58:12.810683  3392 sgd_solver.cpp:105] Iteration 1050, lr = 0.001
I0616 10:00:02.507771  3392 solver.cpp:218] Iteration 1100 (0.455797 iter/s, 109.698s/50 iters), loss = 0.564616
I0616 10:00:02.507875  3392 solver.cpp:237]     Train net output #0: loss = 0.564616 (* 1 = 0.564616 loss)
I0616 10:00:02.507887  3392 sgd_solver.cpp:105] Iteration 1100, lr = 0.001
I0616 10:01:52.195849  3392 solver.cpp:218] Iteration 1150 (0.455835 iter/s, 109.689s/50 iters), loss = 0.46848
I0616 10:01:52.195937  3392 solver.cpp:237]     Train net output #0: loss = 0.46848 (* 1 = 0.46848 loss)
I0616 10:01:52.195947  3392 sgd_solver.cpp:105] Iteration 1150, lr = 0.001
I0616 10:03:41.877640  3392 solver.cpp:218] Iteration 1200 (0.455861 iter/s, 109.682s/50 iters), loss = 0.57375
I0616 10:03:41.877743  3392 solver.cpp:237]     Train net output #0: loss = 0.57375 (* 1 = 0.57375 loss)
I0616 10:03:41.877754  3392 sgd_solver.cpp:105] Iteration 1200, lr = 0.001
I0616 10:05:31.553903  3392 solver.cpp:218] Iteration 1250 (0.455884 iter/s, 109.677s/50 iters), loss = 0.368605
I0616 10:05:31.553992  3392 solver.cpp:237]     Train net output #0: loss = 0.368605 (* 1 = 0.368605 loss)
I0616 10:05:31.554003  3392 sgd_solver.cpp:105] Iteration 1250, lr = 0.001
I0616 10:07:17.133437  3398 data_layer.cpp:73] Restarting data prefetching from start.
I0616 10:07:21.273926  3392 solver.cpp:218] Iteration 1300 (0.455702 iter/s, 109.721s/50 iters), loss = 0.539551
I0616 10:07:21.273991  3392 solver.cpp:237]     Train net output #0: loss = 0.539551 (* 1 = 0.539551 loss)
I0616 10:07:21.274003  3392 sgd_solver.cpp:105] Iteration 1300, lr = 0.001
I0616 10:09:10.981163  3392 solver.cpp:218] Iteration 1350 (0.455755 iter/s, 109.708s/50 iters), loss = 0.508974
I0616 10:09:10.981258  3392 solver.cpp:237]     Train net output #0: loss = 0.508974 (* 1 = 0.508974 loss)
I0616 10:09:10.981273  3392 sgd_solver.cpp:105] Iteration 1350, lr = 0.001
I0616 10:11:00.656769  3392 solver.cpp:218] Iteration 1400 (0.455887 iter/s, 109.676s/50 iters), loss = 0.377025
I0616 10:11:00.656934  3392 solver.cpp:237]     Train net output #0: loss = 0.377025 (* 1 = 0.377025 loss)
I0616 10:11:00.656949  3392 sgd_solver.cpp:105] Iteration 1400, lr = 0.001
I0616 10:12:50.335335  3392 solver.cpp:218] Iteration 1450 (0.455875 iter/s, 109.679s/50 iters), loss = 0.429429
I0616 10:12:50.335539  3392 solver.cpp:237]     Train net output #0: loss = 0.429429 (* 1 = 0.429429 loss)
I0616 10:12:50.335562  3392 sgd_solver.cpp:105] Iteration 1450, lr = 0.001
I0616 10:14:40.008558  3392 solver.cpp:218] Iteration 1500 (0.455898 iter/s, 109.674s/50 iters), loss = 0.602228
I0616 10:14:40.008642  3392 solver.cpp:237]     Train net output #0: loss = 0.602228 (* 1 = 0.602228 loss)
I0616 10:14:40.008657  3392 sgd_solver.cpp:105] Iteration 1500, lr = 0.001
I0616 10:16:29.654175  3392 solver.cpp:218] Iteration 1550 (0.456012 iter/s, 109.646s/50 iters), loss = 0.535836
I0616 10:16:29.654278  3392 solver.cpp:237]     Train net output #0: loss = 0.535836 (* 1 = 0.535836 loss)
I0616 10:16:29.654291  3392 sgd_solver.cpp:105] Iteration 1550, lr = 0.001
I0616 10:18:19.281179  3392 solver.cpp:218] Iteration 1600 (0.456089 iter/s, 109.628s/50 iters), loss = 0.393436
I0616 10:18:19.281297  3392 solver.cpp:237]     Train net output #0: loss = 0.393436 (* 1 = 0.393436 loss)
I0616 10:18:19.281314  3392 sgd_solver.cpp:105] Iteration 1600, lr = 0.001
I0616 10:19:09.997761  3398 data_layer.cpp:73] Restarting data prefetching from start.
I0616 10:20:08.975594  3392 solver.cpp:218] Iteration 1650 (0.455809 iter/s, 109.695s/50 iters), loss = 0.382535
I0616 10:20:08.975687  3392 solver.cpp:237]     Train net output #0: loss = 0.382535 (* 1 = 0.382535 loss)
I0616 10:20:08.975703  3392 sgd_solver.cpp:105] Iteration 1650, lr = 0.001
I0616 10:21:58.639583  3392 solver.cpp:218] Iteration 1700 (0.455935 iter/s, 109.665s/50 iters), loss = 0.417796
I0616 10:21:58.639696  3392 solver.cpp:237]     Train net output #0: loss = 0.417796 (* 1 = 0.417796 loss)
I0616 10:21:58.639708  3392 sgd_solver.cpp:105] Iteration 1700, lr = 0.001
I0616 10:23:48.279741  3392 solver.cpp:218] Iteration 1750 (0.456035 iter/s, 109.641s/50 iters), loss = 0.469588
I0616 10:23:48.279832  3392 solver.cpp:237]     Train net output #0: loss = 0.469588 (* 1 = 0.469588 loss)
I0616 10:23:48.279848  3392 sgd_solver.cpp:105] Iteration 1750, lr = 0.001
I0616 10:25:37.945073  3392 solver.cpp:218] Iteration 1800 (0.45593 iter/s, 109.666s/50 iters), loss = 0.391922
I0616 10:25:37.945209  3392 solver.cpp:237]     Train net output #0: loss = 0.391922 (* 1 = 0.391922 loss)
I0616 10:25:37.945237  3392 sgd_solver.cpp:105] Iteration 1800, lr = 0.001
I0616 10:27:27.614944  3392 solver.cpp:218] Iteration 1850 (0.455911 iter/s, 109.67s/50 iters), loss = 0.388134
I0616 10:27:27.615067  3392 solver.cpp:237]     Train net output #0: loss = 0.388134 (* 1 = 0.388134 loss)
I0616 10:27:27.615084  3392 sgd_solver.cpp:105] Iteration 1850, lr = 0.001
I0616 10:29:17.280254  3392 solver.cpp:218] Iteration 1900 (0.45593 iter/s, 109.666s/50 iters), loss = 0.370229
I0616 10:29:17.280359  3392 solver.cpp:237]     Train net output #0: loss = 0.370229 (* 1 = 0.370229 loss)
I0616 10:29:17.280371  3392 sgd_solver.cpp:105] Iteration 1900, lr = 0.001
I0616 10:31:05.052489  3398 data_layer.cpp:73] Restarting data prefetching from start.
I0616 10:31:06.972700  3392 solver.cpp:218] Iteration 1950 (0.455817 iter/s, 109.693s/50 iters), loss = 0.44839
I0616 10:31:06.972766  3392 solver.cpp:237]     Train net output #0: loss = 0.44839 (* 1 = 0.44839 loss)
I0616 10:31:06.972777  3392 sgd_solver.cpp:105] Iteration 1950, lr = 0.001
I0616 10:32:53.824179  3392 solver.cpp:330] Iteration 2000, Testing net (#0)
I0616 10:33:38.190557  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 10:34:23.253867  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 10:35:08.876252  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 10:35:53.920075  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 10:36:38.988494  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 10:37:24.573403  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 10:38:09.620954  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 10:38:54.696552  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 10:39:40.310091  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 10:40:25.410521  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 10:41:10.524844  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 10:41:56.124006  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 10:41:57.706390  3392 solver.cpp:397]     Test net output #0: accuracy = 0.797922
I0616 10:41:57.706440  3392 solver.cpp:397]     Test net output #1: loss = 0.433043 (* 1 = 0.433043 loss)
I0616 10:41:59.689091  3392 solver.cpp:218] Iteration 2000 (0.0766025 iter/s, 652.721s/50 iters), loss = 0.363165
I0616 10:41:59.689159  3392 solver.cpp:237]     Train net output #0: loss = 0.363165 (* 1 = 0.363165 loss)
I0616 10:41:59.689172  3392 sgd_solver.cpp:105] Iteration 2000, lr = 0.001
I0616 10:43:49.314687  3392 solver.cpp:218] Iteration 2050 (0.456095 iter/s, 109.626s/50 iters), loss = 0.408394
I0616 10:43:49.314801  3392 solver.cpp:237]     Train net output #0: loss = 0.408394 (* 1 = 0.408394 loss)
I0616 10:43:49.314816  3392 sgd_solver.cpp:105] Iteration 2050, lr = 0.001
I0616 10:45:38.985422  3392 solver.cpp:218] Iteration 2100 (0.455908 iter/s, 109.671s/50 iters), loss = 0.306648
I0616 10:45:38.985528  3392 solver.cpp:237]     Train net output #0: loss = 0.306648 (* 1 = 0.306648 loss)
I0616 10:45:38.985544  3392 sgd_solver.cpp:105] Iteration 2100, lr = 0.001
I0616 10:47:28.649807  3392 solver.cpp:218] Iteration 2150 (0.455934 iter/s, 109.665s/50 iters), loss = 0.449917
I0616 10:47:28.649899  3392 solver.cpp:237]     Train net output #0: loss = 0.449917 (* 1 = 0.449917 loss)
I0616 10:47:28.649915  3392 sgd_solver.cpp:105] Iteration 2150, lr = 0.001
I0616 10:49:18.272357  3392 solver.cpp:218] Iteration 2200 (0.456108 iter/s, 109.623s/50 iters), loss = 0.370586
I0616 10:49:18.272444  3392 solver.cpp:237]     Train net output #0: loss = 0.370586 (* 1 = 0.370586 loss)
I0616 10:49:18.272454  3392 sgd_solver.cpp:105] Iteration 2200, lr = 0.001
I0616 10:51:07.976853  3392 solver.cpp:218] Iteration 2250 (0.455768 iter/s, 109.705s/50 iters), loss = 0.36505
I0616 10:51:07.976970  3392 solver.cpp:237]     Train net output #0: loss = 0.36505 (* 1 = 0.36505 loss)
I0616 10:51:07.976987  3392 sgd_solver.cpp:105] Iteration 2250, lr = 0.001
I0616 10:52:00.926864  3398 data_layer.cpp:73] Restarting data prefetching from start.
I0616 10:52:57.691684  3392 solver.cpp:218] Iteration 2300 (0.455725 iter/s, 109.715s/50 iters), loss = 0.443897
I0616 10:52:57.691771  3392 solver.cpp:237]     Train net output #0: loss = 0.443897 (* 1 = 0.443897 loss)
I0616 10:52:57.691783  3392 sgd_solver.cpp:105] Iteration 2300, lr = 0.001
I0616 10:54:47.641976  3392 solver.cpp:218] Iteration 2350 (0.454749 iter/s, 109.951s/50 iters), loss = 0.388086
I0616 10:54:47.642168  3392 solver.cpp:237]     Train net output #0: loss = 0.388086 (* 1 = 0.388086 loss)
I0616 10:54:47.642187  3392 sgd_solver.cpp:105] Iteration 2350, lr = 0.001
I0616 10:56:37.308903  3392 solver.cpp:218] Iteration 2400 (0.455928 iter/s, 109.667s/50 iters), loss = 0.408568
I0616 10:56:37.308998  3392 solver.cpp:237]     Train net output #0: loss = 0.408568 (* 1 = 0.408568 loss)
I0616 10:56:37.309021  3392 sgd_solver.cpp:105] Iteration 2400, lr = 0.001
I0616 10:58:27.012534  3392 solver.cpp:218] Iteration 2450 (0.455772 iter/s, 109.704s/50 iters), loss = 0.285013
I0616 10:58:27.012727  3392 solver.cpp:237]     Train net output #0: loss = 0.285013 (* 1 = 0.285013 loss)
I0616 10:58:27.012747  3392 sgd_solver.cpp:105] Iteration 2450, lr = 0.001
I0616 11:00:16.687688  3392 solver.cpp:218] Iteration 2500 (0.455891 iter/s, 109.675s/50 iters), loss = 0.449953
I0616 11:00:16.687782  3392 solver.cpp:237]     Train net output #0: loss = 0.449953 (* 1 = 0.449953 loss)
I0616 11:00:16.687798  3392 sgd_solver.cpp:105] Iteration 2500, lr = 0.0001
I0616 11:02:06.514223  3392 solver.cpp:218] Iteration 2550 (0.455262 iter/s, 109.827s/50 iters), loss = 0.292538
I0616 11:02:06.514348  3392 solver.cpp:237]     Train net output #0: loss = 0.292538 (* 1 = 0.292538 loss)
I0616 11:02:06.514366  3392 sgd_solver.cpp:105] Iteration 2550, lr = 0.0001
I0616 11:03:56.204658  3392 solver.cpp:218] Iteration 2600 (0.455827 iter/s, 109.691s/50 iters), loss = 0.406024
I0616 11:03:56.204738  3392 solver.cpp:237]     Train net output #0: loss = 0.406024 (* 1 = 0.406024 loss)
I0616 11:03:56.204748  3392 sgd_solver.cpp:105] Iteration 2600, lr = 0.0001
I0616 11:03:56.485373  3398 data_layer.cpp:73] Restarting data prefetching from start.
I0616 11:05:45.920471  3392 solver.cpp:218] Iteration 2650 (0.455721 iter/s, 109.716s/50 iters), loss = 0.277514
I0616 11:05:45.920660  3392 solver.cpp:237]     Train net output #0: loss = 0.277514 (* 1 = 0.277514 loss)
I0616 11:05:45.920680  3392 sgd_solver.cpp:105] Iteration 2650, lr = 0.0001
I0616 11:07:35.619045  3392 solver.cpp:218] Iteration 2700 (0.455793 iter/s, 109.699s/50 iters), loss = 0.339224
I0616 11:07:35.619244  3392 solver.cpp:237]     Train net output #0: loss = 0.339224 (* 1 = 0.339224 loss)
I0616 11:07:35.619271  3392 sgd_solver.cpp:105] Iteration 2700, lr = 0.0001
I0616 11:09:25.324033  3392 solver.cpp:218] Iteration 2750 (0.455766 iter/s, 109.705s/50 iters), loss = 0.472058
I0616 11:09:25.324134  3392 solver.cpp:237]     Train net output #0: loss = 0.472058 (* 1 = 0.472058 loss)
I0616 11:09:25.324152  3392 sgd_solver.cpp:105] Iteration 2750, lr = 0.0001
I0616 11:11:15.015079  3392 solver.cpp:218] Iteration 2800 (0.455823 iter/s, 109.692s/50 iters), loss = 0.403511
I0616 11:11:15.015278  3392 solver.cpp:237]     Train net output #0: loss = 0.403511 (* 1 = 0.403511 loss)
I0616 11:11:15.015295  3392 sgd_solver.cpp:105] Iteration 2800, lr = 0.0001
I0616 11:13:04.680994  3392 solver.cpp:218] Iteration 2850 (0.455928 iter/s, 109.666s/50 iters), loss = 0.267364
I0616 11:13:04.681084  3392 solver.cpp:237]     Train net output #0: loss = 0.267364 (* 1 = 0.267364 loss)
I0616 11:13:04.681102  3392 sgd_solver.cpp:105] Iteration 2850, lr = 0.0001
I0616 11:14:54.365931  3392 solver.cpp:218] Iteration 2900 (0.455848 iter/s, 109.686s/50 iters), loss = 0.35928
I0616 11:14:54.366122  3392 solver.cpp:237]     Train net output #0: loss = 0.35928 (* 1 = 0.35928 loss)
I0616 11:14:54.366135  3392 sgd_solver.cpp:105] Iteration 2900, lr = 0.0001
I0616 11:15:49.527542  3398 data_layer.cpp:73] Restarting data prefetching from start.
I0616 11:16:44.090812  3392 solver.cpp:218] Iteration 2950 (0.455684 iter/s, 109.725s/50 iters), loss = 0.312517
I0616 11:16:44.090911  3392 solver.cpp:237]     Train net output #0: loss = 0.312517 (* 1 = 0.312517 loss)
I0616 11:16:44.090930  3392 sgd_solver.cpp:105] Iteration 2950, lr = 0.0001
I0616 11:18:30.886832  3392 solver.cpp:330] Iteration 3000, Testing net (#0)
I0616 11:19:15.243222  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 11:20:00.339032  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 11:20:45.951253  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 11:21:30.984995  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 11:22:16.046358  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 11:23:01.675058  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 11:23:46.793056  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 11:24:31.862644  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 11:25:17.539443  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 11:26:02.634510  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 11:26:47.684715  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 11:27:33.272204  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 11:27:34.860952  3392 solver.cpp:397]     Test net output #0: accuracy = 0.841641
I0616 11:27:34.861004  3392 solver.cpp:397]     Test net output #1: loss = 0.349926 (* 1 = 0.349926 loss)
I0616 11:27:36.858232  3392 solver.cpp:218] Iteration 3000 (0.0765965 iter/s, 652.771s/50 iters), loss = 0.368913
I0616 11:27:36.858297  3392 solver.cpp:237]     Train net output #0: loss = 0.368913 (* 1 = 0.368913 loss)
I0616 11:27:36.858307  3392 sgd_solver.cpp:105] Iteration 3000, lr = 0.0001
I0616 11:29:26.750773  3392 solver.cpp:218] Iteration 3050 (0.454988 iter/s, 109.893s/50 iters), loss = 0.437004
I0616 11:29:26.750859  3392 solver.cpp:237]     Train net output #0: loss = 0.437004 (* 1 = 0.437004 loss)
I0616 11:29:26.750869  3392 sgd_solver.cpp:105] Iteration 3050, lr = 0.0001
I0616 11:31:16.467838  3392 solver.cpp:218] Iteration 3100 (0.455716 iter/s, 109.718s/50 iters), loss = 0.435524
I0616 11:31:16.467941  3392 solver.cpp:237]     Train net output #0: loss = 0.435524 (* 1 = 0.435524 loss)
I0616 11:31:16.467952  3392 sgd_solver.cpp:105] Iteration 3100, lr = 0.0001
I0616 11:33:06.322993  3392 solver.cpp:218] Iteration 3150 (0.455143 iter/s, 109.856s/50 iters), loss = 0.363704
I0616 11:33:06.323096  3392 solver.cpp:237]     Train net output #0: loss = 0.363704 (* 1 = 0.363704 loss)
I0616 11:33:06.323119  3392 sgd_solver.cpp:105] Iteration 3150, lr = 0.0001
I0616 11:34:55.985970  3392 solver.cpp:218] Iteration 3200 (0.45594 iter/s, 109.664s/50 iters), loss = 0.300308
I0616 11:34:55.986062  3392 solver.cpp:237]     Train net output #0: loss = 0.300308 (* 1 = 0.300308 loss)
I0616 11:34:55.986073  3392 sgd_solver.cpp:105] Iteration 3200, lr = 0.0001
I0616 11:36:45.651532  3392 solver.cpp:218] Iteration 3250 (0.45593 iter/s, 109.666s/50 iters), loss = 0.316066
I0616 11:36:45.651723  3392 solver.cpp:237]     Train net output #0: loss = 0.316066 (* 1 = 0.316066 loss)
I0616 11:36:45.651742  3392 sgd_solver.cpp:105] Iteration 3250, lr = 0.0001
I0616 11:36:48.132005  3398 data_layer.cpp:73] Restarting data prefetching from start.
I0616 11:38:35.321679  3392 solver.cpp:218] Iteration 3300 (0.455911 iter/s, 109.671s/50 iters), loss = 0.329261
I0616 11:38:35.321770  3392 solver.cpp:237]     Train net output #0: loss = 0.329261 (* 1 = 0.329261 loss)
I0616 11:38:35.321782  3392 sgd_solver.cpp:105] Iteration 3300, lr = 0.0001
I0616 11:40:25.002836  3392 solver.cpp:218] Iteration 3350 (0.455864 iter/s, 109.682s/50 iters), loss = 0.283271
I0616 11:40:25.002939  3392 solver.cpp:237]     Train net output #0: loss = 0.283271 (* 1 = 0.283271 loss)
I0616 11:40:25.002954  3392 sgd_solver.cpp:105] Iteration 3350, lr = 0.0001
I0616 11:42:14.684346  3392 solver.cpp:218] Iteration 3400 (0.455863 iter/s, 109.682s/50 iters), loss = 0.459539
I0616 11:42:14.684504  3392 solver.cpp:237]     Train net output #0: loss = 0.459539 (* 1 = 0.459539 loss)
I0616 11:42:14.684516  3392 sgd_solver.cpp:105] Iteration 3400, lr = 0.0001
I0616 11:44:04.359594  3392 solver.cpp:218] Iteration 3450 (0.45589 iter/s, 109.676s/50 iters), loss = 0.421388
I0616 11:44:04.359684  3392 solver.cpp:237]     Train net output #0: loss = 0.421388 (* 1 = 0.421388 loss)
I0616 11:44:04.359695  3392 sgd_solver.cpp:105] Iteration 3450, lr = 0.0001
I0616 11:45:54.020723  3392 solver.cpp:218] Iteration 3500 (0.455948 iter/s, 109.662s/50 iters), loss = 0.301508
I0616 11:45:54.020830  3392 solver.cpp:237]     Train net output #0: loss = 0.301508 (* 1 = 0.301508 loss)
I0616 11:45:54.020851  3392 sgd_solver.cpp:105] Iteration 3500, lr = 0.0001
I0616 11:47:43.706215  3392 solver.cpp:218] Iteration 3550 (0.455847 iter/s, 109.686s/50 iters), loss = 0.335333
I0616 11:47:43.706338  3392 solver.cpp:237]     Train net output #0: loss = 0.335333 (* 1 = 0.335333 loss)
I0616 11:47:43.706357  3392 sgd_solver.cpp:105] Iteration 3550, lr = 0.0001
I0616 11:48:41.015842  3398 data_layer.cpp:73] Restarting data prefetching from start.
I0616 11:49:33.381399  3392 solver.cpp:218] Iteration 3600 (0.455889 iter/s, 109.676s/50 iters), loss = 0.540044
I0616 11:49:33.381593  3392 solver.cpp:237]     Train net output #0: loss = 0.540044 (* 1 = 0.540044 loss)
I0616 11:49:33.381613  3392 sgd_solver.cpp:105] Iteration 3600, lr = 0.0001
I0616 11:51:23.069883  3392 solver.cpp:218] Iteration 3650 (0.455834 iter/s, 109.689s/50 iters), loss = 0.33006
I0616 11:51:23.070070  3392 solver.cpp:237]     Train net output #0: loss = 0.33006 (* 1 = 0.33006 loss)
I0616 11:51:23.070083  3392 sgd_solver.cpp:105] Iteration 3650, lr = 0.0001
I0616 11:53:12.754925  3392 solver.cpp:218] Iteration 3700 (0.455849 iter/s, 109.686s/50 iters), loss = 0.338378
I0616 11:53:12.755043  3392 solver.cpp:237]     Train net output #0: loss = 0.338378 (* 1 = 0.338378 loss)
I0616 11:53:12.755061  3392 sgd_solver.cpp:105] Iteration 3700, lr = 0.0001
I0616 11:55:02.366406  3392 solver.cpp:218] Iteration 3750 (0.456154 iter/s, 109.612s/50 iters), loss = 0.252398
I0616 11:55:02.366503  3392 solver.cpp:237]     Train net output #0: loss = 0.252398 (* 1 = 0.252398 loss)
I0616 11:55:02.366523  3392 sgd_solver.cpp:105] Iteration 3750, lr = 0.0001
I0616 11:56:52.002912  3392 solver.cpp:218] Iteration 3800 (0.45605 iter/s, 109.637s/50 iters), loss = 0.375093
I0616 11:56:52.003005  3392 solver.cpp:237]     Train net output #0: loss = 0.375093 (* 1 = 0.375093 loss)
I0616 11:56:52.003033  3392 sgd_solver.cpp:105] Iteration 3800, lr = 0.0001
I0616 11:58:41.665256  3392 solver.cpp:218] Iteration 3850 (0.455943 iter/s, 109.663s/50 iters), loss = 0.277279
I0616 11:58:41.665397  3392 solver.cpp:237]     Train net output #0: loss = 0.277279 (* 1 = 0.277279 loss)
I0616 11:58:41.665431  3392 sgd_solver.cpp:105] Iteration 3850, lr = 0.0001
I0616 12:00:31.302398  3392 solver.cpp:218] Iteration 3900 (0.456048 iter/s, 109.638s/50 iters), loss = 0.300509
I0616 12:00:31.302487  3392 solver.cpp:237]     Train net output #0: loss = 0.300509 (* 1 = 0.300509 loss)
I0616 12:00:31.302498  3392 sgd_solver.cpp:105] Iteration 3900, lr = 0.0001
I0616 12:00:35.971953  3398 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:02:20.926472  3392 solver.cpp:218] Iteration 3950 (0.456102 iter/s, 109.625s/50 iters), loss = 0.328808
I0616 12:02:20.926558  3392 solver.cpp:237]     Train net output #0: loss = 0.328808 (* 1 = 0.328808 loss)
I0616 12:02:20.926570  3392 sgd_solver.cpp:105] Iteration 3950, lr = 0.0001
I0616 12:04:07.729621  3392 solver.cpp:330] Iteration 4000, Testing net (#0)
I0616 12:04:52.280422  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:05:37.300995  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:06:22.837087  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:07:07.872366  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:07:53.374635  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:08:38.393460  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:09:23.465718  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:10:08.991160  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:10:53.997092  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:11:38.992164  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:12:24.518957  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:13:09.537858  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:13:11.114722  3392 solver.cpp:397]     Test net output #0: accuracy = 0.854122
I0616 12:13:11.114771  3392 solver.cpp:397]     Test net output #1: loss = 0.327876 (* 1 = 0.327876 loss)
I0616 12:13:13.089777  3392 solver.cpp:218] Iteration 4000 (0.0766677 iter/s, 652.165s/50 iters), loss = 0.298704
I0616 12:13:13.089840  3392 solver.cpp:237]     Train net output #0: loss = 0.298704 (* 1 = 0.298704 loss)
I0616 12:13:13.089867  3392 sgd_solver.cpp:105] Iteration 4000, lr = 0.0001
I0616 12:15:02.606034  3392 solver.cpp:218] Iteration 4050 (0.456551 iter/s, 109.517s/50 iters), loss = 0.370593
I0616 12:15:02.606120  3392 solver.cpp:237]     Train net output #0: loss = 0.370593 (* 1 = 0.370593 loss)
I0616 12:15:02.606132  3392 sgd_solver.cpp:105] Iteration 4050, lr = 0.0001
I0616 12:16:52.096962  3392 solver.cpp:218] Iteration 4100 (0.456657 iter/s, 109.491s/50 iters), loss = 0.329558
I0616 12:16:52.097067  3392 solver.cpp:237]     Train net output #0: loss = 0.329558 (* 1 = 0.329558 loss)
I0616 12:16:52.097090  3392 sgd_solver.cpp:105] Iteration 4100, lr = 0.0001
I0616 12:18:41.803164  3392 solver.cpp:218] Iteration 4150 (0.45576 iter/s, 109.707s/50 iters), loss = 0.242689
I0616 12:18:41.803253  3392 solver.cpp:237]     Train net output #0: loss = 0.242689 (* 1 = 0.242689 loss)
I0616 12:18:41.803266  3392 sgd_solver.cpp:105] Iteration 4150, lr = 0.0001
I0616 12:20:31.468927  3392 solver.cpp:218] Iteration 4200 (0.455929 iter/s, 109.666s/50 iters), loss = 0.360336
I0616 12:20:31.469069  3392 solver.cpp:237]     Train net output #0: loss = 0.360336 (* 1 = 0.360336 loss)
I0616 12:20:31.469084  3392 sgd_solver.cpp:105] Iteration 4200, lr = 0.0001
I0616 12:21:30.977651  3398 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:22:21.145735  3392 solver.cpp:218] Iteration 4250 (0.455883 iter/s, 109.677s/50 iters), loss = 0.254424
I0616 12:22:21.145853  3392 solver.cpp:237]     Train net output #0: loss = 0.254424 (* 1 = 0.254424 loss)
I0616 12:22:21.145872  3392 sgd_solver.cpp:105] Iteration 4250, lr = 0.0001
I0616 12:24:10.850322  3392 solver.cpp:218] Iteration 4300 (0.455768 iter/s, 109.705s/50 iters), loss = 0.438437
I0616 12:24:10.850415  3392 solver.cpp:237]     Train net output #0: loss = 0.438437 (* 1 = 0.438437 loss)
I0616 12:24:10.850425  3392 sgd_solver.cpp:105] Iteration 4300, lr = 0.0001
I0616 12:26:00.532454  3392 solver.cpp:218] Iteration 4350 (0.455861 iter/s, 109.683s/50 iters), loss = 0.317195
I0616 12:26:00.532562  3392 solver.cpp:237]     Train net output #0: loss = 0.317195 (* 1 = 0.317195 loss)
I0616 12:26:00.532583  3392 sgd_solver.cpp:105] Iteration 4350, lr = 0.0001
I0616 12:27:50.268451  3392 solver.cpp:218] Iteration 4400 (0.455637 iter/s, 109.736s/50 iters), loss = 0.209661
I0616 12:27:50.268553  3392 solver.cpp:237]     Train net output #0: loss = 0.209661 (* 1 = 0.209661 loss)
I0616 12:27:50.268573  3392 sgd_solver.cpp:105] Iteration 4400, lr = 0.0001
I0616 12:29:39.951683  3392 solver.cpp:218] Iteration 4450 (0.455856 iter/s, 109.684s/50 iters), loss = 0.297751
I0616 12:29:39.951877  3392 solver.cpp:237]     Train net output #0: loss = 0.297751 (* 1 = 0.297751 loss)
I0616 12:29:39.951896  3392 sgd_solver.cpp:105] Iteration 4450, lr = 0.0001
I0616 12:31:29.682950  3392 solver.cpp:218] Iteration 4500 (0.455657 iter/s, 109.732s/50 iters), loss = 0.2755
I0616 12:31:29.683043  3392 solver.cpp:237]     Train net output #0: loss = 0.2755 (* 1 = 0.2755 loss)
I0616 12:31:29.683056  3392 sgd_solver.cpp:105] Iteration 4500, lr = 0.0001
I0616 12:33:19.368952  3392 solver.cpp:218] Iteration 4550 (0.455845 iter/s, 109.687s/50 iters), loss = 0.279242
I0616 12:33:19.369072  3392 solver.cpp:237]     Train net output #0: loss = 0.279242 (* 1 = 0.279242 loss)
I0616 12:33:19.369083  3392 sgd_solver.cpp:105] Iteration 4550, lr = 0.0001
I0616 12:33:26.232818  3398 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:35:09.067369  3392 solver.cpp:218] Iteration 4600 (0.455793 iter/s, 109.699s/50 iters), loss = 0.331742
I0616 12:35:09.067461  3392 solver.cpp:237]     Train net output #0: loss = 0.331742 (* 1 = 0.331742 loss)
I0616 12:35:09.067472  3392 sgd_solver.cpp:105] Iteration 4600, lr = 0.0001
I0616 12:36:58.707626  3392 solver.cpp:218] Iteration 4650 (0.456035 iter/s, 109.641s/50 iters), loss = 0.219362
I0616 12:36:58.707713  3392 solver.cpp:237]     Train net output #0: loss = 0.219362 (* 1 = 0.219362 loss)
I0616 12:36:58.707726  3392 sgd_solver.cpp:105] Iteration 4650, lr = 0.0001
I0616 12:38:48.336594  3392 solver.cpp:218] Iteration 4700 (0.456082 iter/s, 109.629s/50 iters), loss = 0.257251
I0616 12:38:48.336710  3392 solver.cpp:237]     Train net output #0: loss = 0.257251 (* 1 = 0.257251 loss)
I0616 12:38:48.336729  3392 sgd_solver.cpp:105] Iteration 4700, lr = 0.0001
I0616 12:40:37.982297  3392 solver.cpp:218] Iteration 4750 (0.456012 iter/s, 109.646s/50 iters), loss = 0.3184
I0616 12:40:37.982403  3392 solver.cpp:237]     Train net output #0: loss = 0.3184 (* 1 = 0.3184 loss)
I0616 12:40:37.982417  3392 sgd_solver.cpp:105] Iteration 4750, lr = 0.0001
I0616 12:42:27.649646  3392 solver.cpp:218] Iteration 4800 (0.455922 iter/s, 109.668s/50 iters), loss = 0.25618
I0616 12:42:27.649734  3392 solver.cpp:237]     Train net output #0: loss = 0.25618 (* 1 = 0.25618 loss)
I0616 12:42:27.649744  3392 sgd_solver.cpp:105] Iteration 4800, lr = 0.0001
I0616 12:44:17.292939  3392 solver.cpp:218] Iteration 4850 (0.456022 iter/s, 109.644s/50 iters), loss = 0.288771
I0616 12:44:17.293063  3392 solver.cpp:237]     Train net output #0: loss = 0.288771 (* 1 = 0.288771 loss)
I0616 12:44:17.293084  3392 sgd_solver.cpp:105] Iteration 4850, lr = 0.0001
I0616 12:45:18.949321  3398 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:46:06.943722  3392 solver.cpp:218] Iteration 4900 (0.455991 iter/s, 109.651s/50 iters), loss = 0.391161
I0616 12:46:06.943815  3392 solver.cpp:237]     Train net output #0: loss = 0.391161 (* 1 = 0.391161 loss)
I0616 12:46:06.943830  3392 sgd_solver.cpp:105] Iteration 4900, lr = 0.0001
I0616 12:47:56.605464  3392 solver.cpp:218] Iteration 4950 (0.455945 iter/s, 109.662s/50 iters), loss = 0.400952
I0616 12:47:56.605581  3392 solver.cpp:237]     Train net output #0: loss = 0.400952 (* 1 = 0.400952 loss)
I0616 12:47:56.605599  3392 sgd_solver.cpp:105] Iteration 4950, lr = 0.0001
I0616 12:49:43.386932  3392 solver.cpp:447] Snapshotting to binary proto file /home/jondan/Documents/Ohjelmat/haalarimerkkiGo/caffe_model_1_iter_5000.caffemodel
I0616 12:49:45.323267  3392 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/jondan/Documents/Ohjelmat/haalarimerkkiGo/caffe_model_1_iter_5000.solverstate
I0616 12:49:45.708884  3392 solver.cpp:330] Iteration 5000, Testing net (#0)
I0616 12:50:29.533727  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:51:15.042387  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:52:00.062328  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:52:45.090282  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:53:30.646441  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:54:15.688804  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:55:00.710398  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:55:46.266628  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:56:31.318619  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:57:16.381268  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:58:01.903770  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:58:46.930716  3399 data_layer.cpp:73] Restarting data prefetching from start.
I0616 12:58:48.494781  3392 solver.cpp:397]     Test net output #0: accuracy = 0.857462
I0616 12:58:48.494827  3392 solver.cpp:397]     Test net output #1: loss = 0.330599 (* 1 = 0.330599 loss)
I0616 12:58:50.473783  3392 solver.cpp:218] Iteration 5000 (0.0764676 iter/s, 653.872s/50 iters), loss = 0.280724
I0616 12:58:50.473853  3392 solver.cpp:237]     Train net output #0: loss = 0.280725 (* 1 = 0.280725 loss)
I0616 12:58:50.473899  3392 sgd_solver.cpp:105] Iteration 5000, lr = 1e-05
I0616 13:00:40.051230  3392 solver.cpp:218] Iteration 5050 (0.456296 iter/s, 109.578s/50 iters), loss = 0.319037
I0616 13:00:40.051368  3392 solver.cpp:237]     Train net output #0: loss = 0.319037 (* 1 = 0.319037 loss)
I0616 13:00:40.051388  3392 sgd_solver.cpp:105] Iteration 5050, lr = 1e-05
I0616 13:02:29.643262  3392 solver.cpp:218] Iteration 5100 (0.456236 iter/s, 109.592s/50 iters), loss = 0.182572
I0616 13:02:29.643368  3392 solver.cpp:237]     Train net output #0: loss = 0.182573 (* 1 = 0.182573 loss)
I0616 13:02:29.643384  3392 sgd_solver.cpp:105] Iteration 5100, lr = 1e-05
